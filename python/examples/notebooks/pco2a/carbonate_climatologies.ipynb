{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1b8777-67ac-4a8c-b436-d2ef4db9a50b",
   "metadata": {},
   "source": [
    "# Carbonate Climatologies using PCO2a sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06cd9f87",
   "metadata": {},
   "outputs": [
    {
     "ename": "NetrcParseError",
     "evalue": "~/.netrc access too permissive: access permissions must restrict access to only the owner (/home/jovyan/.netrc, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNetrcParseError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mooi_data_explorations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_annotations, load_gc_thredds, add_annotation_qc_flags\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mooi_data_explorations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombine_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m combine_datasets\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mooi_data_explorations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muncabled\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocess_pco2a\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pco2a_datalogger\n",
      "File \u001b[0;32m~/ooi-data-explorations/python/ooi_data_explorations/common.py:73\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# load the access credentials\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m     nrc \u001b[38;5;241m=\u001b[39m \u001b[43mnetrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetrc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     AUTH \u001b[38;5;241m=\u001b[39m nrc\u001b[38;5;241m.\u001b[39mauthenticators(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mooinet.oceanobservatories.org\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m AUTH \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/netrc.py:31\u001b[0m, in \u001b[0;36mnetrc.__init__\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m---> 31\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_netrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocale\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/netrc.py:108\u001b[0m, in \u001b[0;36mnetrc._parse\u001b[0;34m(self, file, fp, default_netrc)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m NetrcParseError(\n\u001b[1;32m    104\u001b[0m                 (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~/.netrc file owner (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m current user (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m%\u001b[39m (fowner, user),\n\u001b[1;32m    106\u001b[0m                 file, lexer\u001b[38;5;241m.\u001b[39mlineno)\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (prop\u001b[38;5;241m.\u001b[39mst_mode \u001b[38;5;241m&\u001b[39m (stat\u001b[38;5;241m.\u001b[39mS_IRWXG \u001b[38;5;241m|\u001b[39m stat\u001b[38;5;241m.\u001b[39mS_IRWXO)):\n\u001b[0;32m--> 108\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m NetrcParseError(\n\u001b[1;32m    109\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~/.netrc access too permissive: access\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m permissions must restrict access to only\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the owner\u001b[39m\u001b[38;5;124m\"\u001b[39m, file, lexer\u001b[38;5;241m.\u001b[39mlineno)\n\u001b[1;32m    112\u001b[0m     password \u001b[38;5;241m=\u001b[39m lexer\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNetrcParseError\u001b[0m: ~/.netrc access too permissive: access permissions must restrict access to only the owner (/home/jovyan/.netrc, line 3)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import xarray as xr\n",
    "\n",
    "from ooi_data_explorations.common import get_annotations, load_gc_thredds, add_annotation_qc_flags\n",
    "from ooi_data_explorations.combine_data import combine_datasets\n",
    "from ooi_data_explorations.uncabled.process_pco2a import pco2a_datalogger\n",
    "from ooi_data_explorations.uncabled.process_phsen import phsen_datalogger, phsen_instrument\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f76c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ooi_data_explorations.qartod.climatology import Climatology\n",
    "clm = Climatology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357c99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pco2a(site, node, sensor):\n",
    "    \"\"\"\n",
    "    Download the PCO2A water measurement data files from the OOI Gold Copy \n",
    "    THREDDS server, combine the data from the two different data delivery \n",
    "    methods, and median average the data into daily averages.\n",
    "    \"\"\"\n",
    "    # set the stream names and the regex tag to use to select the data files of interest\n",
    "    tstream = 'pco2a_a_dcl_instrument_water'\n",
    "    rstream = 'pco2a_a_dcl_instrument_water_recovered'\n",
    "    tag = '.*PCO2A.*water.*\\\\.nc$'\n",
    "\n",
    "    # download annotations associated with this site\n",
    "    annotations = get_annotations(site, node, sensor)\n",
    "\n",
    "    # download the telemetered data and re-process it to create a more useful and coherent data set\n",
    "    print('### -- Downloading the telemetered data')\n",
    "    telem = load_gc_thredds(site, node, sensor, 'telemetered', tstream, tag)\n",
    "    telem = pco2a_datalogger(telem)\n",
    "    \n",
    "    # download the recovered host data and re-process it to create a more useful and coherent data set\n",
    "    print('### -- Downloading the recovered_host data')\n",
    "    rhost = load_gc_thredds(site, node, sensor, 'recovered_host', rstream, tag)\n",
    "    rhost = pco2a_datalogger(rhost)\n",
    "\n",
    "    # create a roll-up annotation flag\n",
    "    telem = add_annotation_qc_flags(telem, annotations)\n",
    "    rhost = add_annotation_qc_flags(rhost, annotations)\n",
    "    \n",
    "    # clean-up the data, removing values that are marked as suspect or fail in the annotations\n",
    "    telem = telem.where((telem.partial_pressure_co2_ssw_annotations_qc_results < 3) & \n",
    "                        (telem.rollup_annotations_qc_results < 3))\n",
    "    rhost = rhost.where((rhost.partial_pressure_co2_ssw_annotations_qc_results < 3) & \n",
    "                        (rhost.rollup_annotations_qc_results < 3))\n",
    "\n",
    "    # combine the two datasets into a single, merged time series resampled to daily median averages\n",
    "    merged = combine_datasets(telem, rhost, None, 1440)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1da13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_phsen(site, node, sensor):\n",
    "    \"\"\"\n",
    "    Download the PHSEN data files from the OOI Gold Copy THREDDS server, combine \n",
    "    the data from the three different data delivery methods, and median average \n",
    "    the data into daily averages.\n",
    "    \"\"\"\n",
    "    # download annotations associated with this site\n",
    "    annotations = get_annotations(site, node, sensor)\n",
    "\n",
    "    tag = '.*PHSEN.*\\\\.nc$'\n",
    "    print('### -- Downloading the telemetered data')\n",
    "    telem = load_gc_thredds(site, node, sensor, 'telemetered', 'phsen_abcdef_dcl_instrument', tag)\n",
    "    telem = phsen_datalogger(telem)\n",
    "    \n",
    "    # download the recovered host data and re-process it to create a more useful and coherent data set\n",
    "    print('### -- Downloading the recovered_host data')\n",
    "    rhost = load_gc_thredds(site, node, sensor, 'recovered_host', 'phsen_abcdef_dcl_instrument_recovered', tag)\n",
    "    rhost = phsen_datalogger(rhost)\n",
    "\n",
    "    # download the recovered instrument data and re-process it to create a more useful and coherent data set\n",
    "    print('### -- Downloading the recovered_inst data')\n",
    "    rinst = load_gc_thredds(site, node, sensor, 'recovered_inst', 'phsen_abcdef_instrument', tag)\n",
    "    rinst = phsen_instrument(rinst)\n",
    "    \n",
    "    # create a roll-up annotation flag\n",
    "    telem = add_annotation_qc_flags(telem, annotations)\n",
    "    rhost = add_annotation_qc_flags(rhost, annotations)\n",
    "    rinst = add_annotation_qc_flags(rinst, annotations)\n",
    "\n",
    "    # clean-up the data, removing values that fail the pH quality checks or were marked as fail in the annotations\n",
    "    telem = telem.where((telem.seawater_ph_quality_flag != 4) & (telem.rollup_annotations_qc_results != 4))\n",
    "    rhost = rhost.where((rhost.seawater_ph_quality_flag != 4) & (rhost.rollup_annotations_qc_results != 4))\n",
    "    rinst = rinst.where((rinst.seawater_ph_quality_flag != 4) & (rinst.rollup_annotations_qc_results != 4))\n",
    "    \n",
    "    # combine the three datasets into a single, merged time series resampled to daily median averages\n",
    "    merged = combine_datasets(telem, rhost, rinst, 1440)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4e674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Downloading the PCO2A data from CE02SHSM ###\n",
      "### -- Downloading the telemetered data\n",
      "Downloading 803 data file(s) from the OOI Gold Copy THREDSS catalog\n",
      "Downloading and Processing the Data Files: 100%|██████████| 803/803 [01:13<00:00, 10.89it/s]\n",
      "Merging the data files into a single dataset\n",
      "### -- Downloading the recovered_host data\n",
      "Downloading 23 data file(s) from the OOI Gold Copy THREDSS catalog\n",
      "Downloading and Processing the Data Files: 100%|██████████| 23/23 [00:03<00:00,  6.47it/s]\n",
      "Merging the data files into a single dataset\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "failed to prevent overwriting existing key units in attrs on variable 'time'. This is probably an encoding field used by xarray to describe how a variable is serialized. To proceed, remove this key from the variable's attributes manually.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m### Downloading the PCO2A data from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m ###\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m site)\n\u001b[1;32m     24\u001b[0m pco2a\u001b[38;5;241m.\u001b[39mappend(merge_pco2a(site, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSBD12\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m04-PCO2AA000\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 25\u001b[0m \u001b[43mpco2a\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpco2a_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNETCDF4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh5netcdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# pause, the THREDDS server doesn't like getting hammered\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m### Downloading the PHSEN data from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m ###\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m site)\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/core/dataset.py:2021\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[1;32m   2018\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 2021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[1;32m   2022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2034\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/backends/api.py:1928\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# TODO: figure out how to refactor this logic (here and in save_mfdataset)\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# to avoid this mess of conditionals\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;66;03m# TODO: allow this work (setting up the file for writing array data)\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;66;03m# to be parallelized with dask\u001b[39;00m\n\u001b[0;32m-> 1928\u001b[0m     \u001b[43mdump_to_store\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m autoclose:\n\u001b[1;32m   1932\u001b[0m         store\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/backends/api.py:1975\u001b[0m, in \u001b[0;36mdump_to_store\u001b[0;34m(dataset, store, writer, encoder, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder:\n\u001b[1;32m   1973\u001b[0m     variables, attrs \u001b[38;5;241m=\u001b[39m encoder(variables, attrs)\n\u001b[0;32m-> 1975\u001b[0m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/backends/common.py:454\u001b[0m, in \u001b[0;36mAbstractWritableDataStore.store\u001b[0;34m(self, variables, attributes, check_encoding_set, writer, unlimited_dims)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    452\u001b[0m     writer \u001b[38;5;241m=\u001b[39m ArrayWriter()\n\u001b[0;32m--> 454\u001b[0m variables, attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_attributes(attributes)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_dimensions(variables, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims)\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/backends/common.py:638\u001b[0m, in \u001b[0;36mWritableCFDataStore.encode\u001b[0;34m(self, variables, attributes)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, variables, attributes):\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;66;03m# All NetCDF files get CF encoded by default, without this attempting\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;66;03m# to write times, for example, would fail.\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m     variables, attributes \u001b[38;5;241m=\u001b[39m \u001b[43mcf_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m     variables \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    640\u001b[0m         k: ensure_dtype_not_object(v, name\u001b[38;5;241m=\u001b[39mk) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    641\u001b[0m     }\n\u001b[1;32m    642\u001b[0m     variables \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_variable(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/conventions.py:788\u001b[0m, in \u001b[0;36mcf_encoder\u001b[0;34m(variables, attributes)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;66;03m# add encoding for time bounds variables if present.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m _update_bounds_encoding(variables)\n\u001b[0;32m--> 788\u001b[0m new_vars \u001b[38;5;241m=\u001b[39m {k: encode_cf_variable(v, name\u001b[38;5;241m=\u001b[39mk) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Remove attrs from bounds variables (issue #2921)\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m new_vars\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/conventions.py:788\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;66;03m# add encoding for time bounds variables if present.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m _update_bounds_encoding(variables)\n\u001b[0;32m--> 788\u001b[0m new_vars \u001b[38;5;241m=\u001b[39m {k: \u001b[43mencode_cf_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Remove attrs from bounds variables (issue #2921)\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m new_vars\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/conventions.py:102\u001b[0m, in \u001b[0;36mencode_cf_variable\u001b[0;34m(var, needs_copy, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m ensure_not_multiindex(var, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m coder \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m     93\u001b[0m     CFDatetimeCoder(),\n\u001b[1;32m     94\u001b[0m     CFTimedeltaCoder(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     variables\u001b[38;5;241m.\u001b[39mBooleanCoder(),\n\u001b[1;32m    101\u001b[0m ]:\n\u001b[0;32m--> 102\u001b[0m     var \u001b[38;5;241m=\u001b[39m \u001b[43mcoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr_name \u001b[38;5;129;01min\u001b[39;00m CF_RELATED_DATA:\n\u001b[1;32m    105\u001b[0m     pop_to(var\u001b[38;5;241m.\u001b[39mencoding, var\u001b[38;5;241m.\u001b[39mattrs, attr_name)\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/coding/times.py:1366\u001b[0m, in \u001b[0;36mCFDatetimeCoder.encode\u001b[0;34m(self, variable, name)\u001b[0m\n\u001b[1;32m   1363\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1364\u001b[0m (data, units, calendar) \u001b[38;5;241m=\u001b[39m encode_cf_datetime(data, units, calendar, dtype)\n\u001b[0;32m-> 1366\u001b[0m \u001b[43msafe_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m safe_setitem(attrs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalendar\u001b[39m\u001b[38;5;124m\"\u001b[39m, calendar, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Variable(dims, data, attrs, encoding, fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/coding/common.py:108\u001b[0m, in \u001b[0;36msafe_setitem\u001b[0;34m(dest, key, value, name)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dest:\n\u001b[1;32m    107\u001b[0m     var_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m on variable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed to prevent overwriting existing key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in attrs\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is probably an encoding field used by xarray to describe \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow a variable is serialized. To proceed, remove this key from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe variable\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms attributes manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m     )\n\u001b[1;32m    114\u001b[0m dest[key] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[0;31mValueError\u001b[0m: failed to prevent overwriting existing key units in attrs on variable 'time'. This is probably an encoding field used by xarray to describe how a variable is serialized. To proceed, remove this key from the variable's attributes manually."
     ]
    }
   ],
   "source": [
    "# download the pco2a and phsen data from the 4 Endurance array Coastal Surface Moorings, \n",
    "# merging the data from the different data delivery methods and saving the results to disk\n",
    "# for further analysis.\n",
    "sites = ['CE02SHSM', 'CE04OSSM', 'CE07SHSM', 'CE09OSSM']\n",
    "pco2a = []\n",
    "phsen = []\n",
    "for num, site in enumerate(sites):\n",
    "    # save the PCO2A data to local files in the home directory under ooidata\n",
    "    pco2_path = os.path.join(os.path.expanduser('~'), 'ooidata/%s/buoy/pco2a' % site.lower())\n",
    "    if not os.path.exists(pco2_path):\n",
    "        os.makedirs(pco2_path)\n",
    "    \n",
    "    pco2a_file = os.path.join(pco2_path, '%s.pco2a.merged.nc' % site.lower())\n",
    "\n",
    "    # save the PHSEN data to local files in the home directory under ooidata\n",
    "    ph_path = os.path.join(os.path.expanduser('~'), 'ooidata/%s/nsif/phsen' % site.lower())\n",
    "    if not os.path.exists(ph_path):\n",
    "        os.makedirs(ph_path)\n",
    "\n",
    "    phsen_file = os.path.join(ph_path, '%s.phsen.merged.nc' % site.lower())\n",
    "\n",
    "    # download the data, or ...\n",
    "    print('### Downloading the PCO2A data from %s ###' % site)\n",
    "    pco2a.append(merge_pco2a(site, 'SBD12', '04-PCO2AA000'))\n",
    "    pco2a[num].to_netcdf(pco2a_file, mode='w', format='NETCDF4', engine='h5netcdf')\n",
    "    time.sleep(10)  # pause, the THREDDS server doesn't like getting hammered\n",
    "    \n",
    "    print('### Downloading the PHSEN data from %s ###' % site)\n",
    "    phsen.append(merge_phsen(site, 'RID26', '06-PHSEND000'))\n",
    "    phsen[num].to_netcdf(phsen_file, mode='w', format='NETCDF4', engine='h5netcdf')\n",
    "    time.sleep(10)  # pause, the THREDDS server doesn't like getting hammered\n",
    "\n",
    "    # ... load the already downloaded data\n",
    "    # pco2a.append(xr.load_dataset(pco2a_file))\n",
    "    # phsen.append(xr.load_dataset(phsen_file))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b23aed-2ff9-4bc5-bdf5-5c88bfcf2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3971dc1-8023-456e-8e78-670a067b5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t for t in pco2a[0].attrs.keys() if 'time' in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c8588-6468-4037-bbbc-990dddc3ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pco2a[0].to_netcdf(pco2a_file, mode='w', format='NETCDF4', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748cfb4-2b22-45e4-830d-766311c0a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f543857-67be-460b-b7be-ae48a6cd5cec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "failed to prevent overwriting existing key units in attrs on variable 'time'. This is probably an encoding field used by xarray to describe how a variable is serialized. To proceed, remove this key from the variable's attributes manually.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpco2a\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbleh.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/core/dataset.py:2021\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[1;32m   2018\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 2021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[1;32m   2022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2034\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/backends/api.py:1928\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# TODO: figure out how to refactor this logic (here and in save_mfdataset)\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# to avoid this mess of conditionals\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;66;03m# TODO: allow this work (setting up the file for writing array data)\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;66;03m# to be parallelized with dask\u001b[39;00m\n\u001b[0;32m-> 1928\u001b[0m     \u001b[43mdump_to_store\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m autoclose:\n\u001b[1;32m   1932\u001b[0m         store\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/backends/api.py:1975\u001b[0m, in \u001b[0;36mdump_to_store\u001b[0;34m(dataset, store, writer, encoder, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder:\n\u001b[1;32m   1973\u001b[0m     variables, attrs \u001b[38;5;241m=\u001b[39m encoder(variables, attrs)\n\u001b[0;32m-> 1975\u001b[0m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/backends/common.py:454\u001b[0m, in \u001b[0;36mAbstractWritableDataStore.store\u001b[0;34m(self, variables, attributes, check_encoding_set, writer, unlimited_dims)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    452\u001b[0m     writer \u001b[38;5;241m=\u001b[39m ArrayWriter()\n\u001b[0;32m--> 454\u001b[0m variables, attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_attributes(attributes)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_dimensions(variables, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims)\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/backends/common.py:638\u001b[0m, in \u001b[0;36mWritableCFDataStore.encode\u001b[0;34m(self, variables, attributes)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, variables, attributes):\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;66;03m# All NetCDF files get CF encoded by default, without this attempting\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;66;03m# to write times, for example, would fail.\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m     variables, attributes \u001b[38;5;241m=\u001b[39m \u001b[43mcf_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m     variables \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    640\u001b[0m         k: ensure_dtype_not_object(v, name\u001b[38;5;241m=\u001b[39mk) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    641\u001b[0m     }\n\u001b[1;32m    642\u001b[0m     variables \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_variable(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/conventions.py:788\u001b[0m, in \u001b[0;36mcf_encoder\u001b[0;34m(variables, attributes)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;66;03m# add encoding for time bounds variables if present.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m _update_bounds_encoding(variables)\n\u001b[0;32m--> 788\u001b[0m new_vars \u001b[38;5;241m=\u001b[39m {k: encode_cf_variable(v, name\u001b[38;5;241m=\u001b[39mk) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Remove attrs from bounds variables (issue #2921)\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m new_vars\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/conventions.py:788\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;66;03m# add encoding for time bounds variables if present.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m _update_bounds_encoding(variables)\n\u001b[0;32m--> 788\u001b[0m new_vars \u001b[38;5;241m=\u001b[39m {k: \u001b[43mencode_cf_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Remove attrs from bounds variables (issue #2921)\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m new_vars\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/conventions.py:102\u001b[0m, in \u001b[0;36mencode_cf_variable\u001b[0;34m(var, needs_copy, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m ensure_not_multiindex(var, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m coder \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m     93\u001b[0m     CFDatetimeCoder(),\n\u001b[1;32m     94\u001b[0m     CFTimedeltaCoder(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     variables\u001b[38;5;241m.\u001b[39mBooleanCoder(),\n\u001b[1;32m    101\u001b[0m ]:\n\u001b[0;32m--> 102\u001b[0m     var \u001b[38;5;241m=\u001b[39m \u001b[43mcoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr_name \u001b[38;5;129;01min\u001b[39;00m CF_RELATED_DATA:\n\u001b[1;32m    105\u001b[0m     pop_to(var\u001b[38;5;241m.\u001b[39mencoding, var\u001b[38;5;241m.\u001b[39mattrs, attr_name)\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/coding/times.py:1366\u001b[0m, in \u001b[0;36mCFDatetimeCoder.encode\u001b[0;34m(self, variable, name)\u001b[0m\n\u001b[1;32m   1363\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1364\u001b[0m (data, units, calendar) \u001b[38;5;241m=\u001b[39m encode_cf_datetime(data, units, calendar, dtype)\n\u001b[0;32m-> 1366\u001b[0m \u001b[43msafe_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m safe_setitem(attrs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalendar\u001b[39m\u001b[38;5;124m\"\u001b[39m, calendar, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Variable(dims, data, attrs, encoding, fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/ooi/lib/python3.10/site-packages/xarray/coding/common.py:108\u001b[0m, in \u001b[0;36msafe_setitem\u001b[0;34m(dest, key, value, name)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dest:\n\u001b[1;32m    107\u001b[0m     var_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m on variable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed to prevent overwriting existing key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in attrs\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is probably an encoding field used by xarray to describe \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow a variable is serialized. To proceed, remove this key from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe variable\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms attributes manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m     )\n\u001b[1;32m    114\u001b[0m dest[key] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[0;31mValueError\u001b[0m: failed to prevent overwriting existing key units in attrs on variable 'time'. This is probably an encoding field used by xarray to describe how a variable is serialized. To proceed, remove this key from the variable's attributes manually."
     ]
    }
   ],
   "source": [
    "pco2a[0].to_netcdf('bleh.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5887cce-cd18-4c1b-b25d-060152735e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = merge_pco2a(site, 'SBD12', '04-PCO2AA000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827ea67-3da2-4b34-8b65-8e84babba504",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah.time['units'] = 'Seconds since 1900-01-01T00:00:00.000Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b81a5-32e3-40a2-98ac-341efb9ba46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah.to_netcdf('test_ds.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582834bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup arrays with the fugacity and pH data from Fassbender et al 2018\n",
    "buoy_fco2 = np.array([\n",
    "    [1, 341, 24, 398, 368, 29, 1485],\n",
    "    [2, 358, 30, 221, 343, 38, 1347],\n",
    "    [3, 415, 74, 245, 322, 34, 1295],\n",
    "    [4, 245, 41, 279, 277, 36, 1199],\n",
    "    [5, 204, 33, 484, 279, 41, 1158],\n",
    "    [6, 212, 48, 1080, 260, 51, 1244],\n",
    "    [7, 258, 68, 1461, 281, 57, 1715],\n",
    "    [8, 283, 58, 1648, 276, 52, 1812],\n",
    "    [9, 325, 45, 1346, 316, 51, 1619],\n",
    "    [10, 342, 25, 1028, 330, 47, 1753],\n",
    "    [11, 358, 40, 645, 364, 34, 1506],\n",
    "    [12, 349, 26, 495, 371, 21, 1484]\n",
    "])\n",
    "\n",
    "region_fco2 = np.array([\n",
    "    [1, 358, 57, 373, 120, 361, 163],\n",
    "    [2, 385, 65, 341, 19, 363, 446],\n",
    "    [3, 356, 170, 311, 98, 343, 250],\n",
    "    [4, 264, 7, 277, 23, 320, 66],\n",
    "    [5, 337, 34, 287, 135, 320, 364],\n",
    "    [6, 288, 1700, 287, 3456, 322, 2791],\n",
    "    [7, 282, 6969, 257, 1545, 340, 4026],\n",
    "    [8, 275, 6301, 275, 3614, 330, 1876],\n",
    "    [9, 285, 750, 323, 719, 344, 504],\n",
    "    [10, 359, 5, 350, 24, 344, 88],\n",
    "    [11, 351, 13, 340, 46, 349, 109],\n",
    "    [12, np.nan, 0, np.nan, 0, 357, 29],\n",
    "])\n",
    "\n",
    "buoy_ph = np.array([\n",
    "    [1, 8.07, 0.03, 398, 8.06, 0.03, 1485],\n",
    "    [2, 8.08, 0.03, 222, 8.08, 0.04, 1347],\n",
    "    [3, 8.02, 0.06, 248, 8.11, 0.04, 1295],\n",
    "    [4, 8.22, 0.06, 279, 8.17, 0.05, 1199],\n",
    "    [5, 8.27, 0.06, 495, 8.17, 0.05, 1158],\n",
    "    [6, 8.26, 0.09, 1117, 8.2, 0.07, 1244],\n",
    "    [7, 8.21, 0.09, 1461, 8.17, 0.07, 1715],\n",
    "    [8, 8.17, 0.08, 1648, 8.18, 0.07, 1812],\n",
    "    [9, 8.11, 0.07, 1547, 8.13, 0.06, 1619],\n",
    "    [10, 8.09, 0.03, 1172, 8.11, 0.06, 1753],\n",
    "    [11, 8.06, 0.05, 646, 8.07, 0.04, 1506],\n",
    "    [12, 8.07, 0.03, 496, 8.06, 0.02, 1484],  \n",
    "])\n",
    "\n",
    "region_ph = np.array([\n",
    "    [1, 8.07, 57, 8.06, 120, 8.07, 163],\n",
    "    [2, 8.05, 65, 8.09, 19, 8.07, 446],\n",
    "    [3, 8.07, 170, 8.12, 98, 8.09, 250],\n",
    "    [4, 8.19, 7, 8.16, 23, 8.12, 66],\n",
    "    [5, 8.1, 34, 8.14, 135, 8.12, 358],\n",
    "    [6, 8.15, 1700, 8.15, 3456, 8.11, 2791],\n",
    "    [7, 8.16, 6969, 8.2, 1545, 8.09, 4024],\n",
    "    [8, 8.14, 5585, 8.16, 3059, 8.1, 1770],\n",
    "    [9, 8.16, 749, 8.1, 719, 8.09, 504],\n",
    "    [10, 8.07, 5, 8.08, 24, 8.09, 88],\n",
    "    [11, 8.08, 13, 8.09, 46, 8.08, 109],\n",
    "    [12, np.nan, 0, np.nan, 0, 8.07, 29],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfccbaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the climatological model and setup defaults for plotting the pCO2 and pH data\n",
    "clm = Climatology()\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Plot the PCO2A data alongside Fassbender et al 2018 ######\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.set_size_inches(17, 11)\n",
    "\n",
    "# calculate the monthly climatologies for the Washington Offshore mooring and group the data monthly \n",
    "num = 3\n",
    "clm.fit(pco2a[num], 'partial_pressure_co2_ssw')\n",
    "r2 = r'2-Cycle: R$^2$ = %.3f' % clm.regression['variance_explained'][0]\n",
    "mnthly_pco2 = pco2a[num].resample(time='M').mean()\n",
    "grps_pco2 = mnthly_pco2.groupby('time.month')\n",
    "\n",
    "# Plot the Washington Offshore data\n",
    "for grp in grps_pco2:\n",
    "    axs[0, 0].plot(grp[1].time.to_index().strftime('%m').astype(int), grp[1]['partial_pressure_co2_ssw'],\n",
    "                   'o', color='lightgrey')\n",
    "axs[0, 0].plot(buoy_fco2[:, 0], buoy_fco2[:, 4], '-k', label='Cape Elizabeth')\n",
    "axs[0, 0].plot(buoy_fco2[:, 0], buoy_fco2[:, 4] - buoy_fco2[:, 5], ':k', \n",
    "               buoy_fco2[:, 0], buoy_fco2[:, 4] + buoy_fco2[:, 5], ':k')\n",
    "axs[0, 0].plot(region_fco2[:, 0], region_fco2[:, 3], '-', color='royalblue', label='Outer Coast')\n",
    "axs[0, 0].plot(clm.monthly_fit.index, clm.monthly_fit.values, '-o', color='darkorange', label=r2)\n",
    "axs[0, 0].legend(prop={'size': 12}, loc=1)\n",
    "axs[0, 0].set_title('Washington Offshore')\n",
    "\n",
    "# calculate the monthly climatologies for the Washington Shelf mooring and group the data monthly \n",
    "num = 2\n",
    "clm.fit(pco2a[num], 'partial_pressure_co2_ssw')\n",
    "r2 = '2-Cycle: R$^2$ = %.3f' % clm.regression['variance_explained'][0]\n",
    "mnthly_pco2 = pco2a[num].resample(time='M').mean()\n",
    "grps_pco2 = mnthly_pco2.groupby('time.month')\n",
    "\n",
    "# Plot the Washington Shelf data\n",
    "for grp in grps_pco2:\n",
    "    axs[0, 1].plot(grp[1].time.to_index().strftime('%m').astype(int), grp[1]['partial_pressure_co2_ssw'],\n",
    "                   'o', color='lightgrey')\n",
    "axs[0, 1].plot(buoy_fco2[:, 0], buoy_fco2[:, 4], '-k', label='Cape Elizabeth')\n",
    "axs[0, 1].plot(buoy_fco2[:, 0], buoy_fco2[:, 4] - buoy_fco2[:, 5], ':k', \n",
    "               buoy_fco2[:, 0], buoy_fco2[:, 4] + buoy_fco2[:, 5], ':k')\n",
    "axs[0, 1].plot(region_fco2[:, 0], region_fco2[:, 3], '-', color='royalblue', label='Outer Coast')\n",
    "axs[0, 1].plot(clm.monthly_fit.index, clm.monthly_fit.values, '-o', color='darkorange', label=r2)\n",
    "axs[0, 1].legend(prop={'size': 12}, loc=1)\n",
    "axs[0, 1].set_title('Washington Shelf')\n",
    "\n",
    "# calculate the monthly climatologies for the Oregon Offshore mooring and group the data monthly \n",
    "num = 1\n",
    "clm.fit(pco2a[num], 'partial_pressure_co2_ssw')\n",
    "r2 = '2-Cycle: R$^2$ = %.3f' % clm.regression['variance_explained'][0]\n",
    "mnthly_pco2 = pco2a[num].resample(time='M').mean()\n",
    "grps_pco2 = mnthly_pco2.groupby('time.month')\n",
    "\n",
    "# Plot the Oregon Offshore data\n",
    "for grp in grps_pco2:\n",
    "    axs[1, 0].plot(grp[1].time.to_index().strftime('%m').astype(int), grp[1]['partial_pressure_co2_ssw'],\n",
    "                   'o', color='lightgrey')\n",
    "axs[1, 0].plot(region_fco2[:, 0], region_fco2[:, 5], '-', color='royalblue', label=r'North Pacific')\n",
    "axs[1, 0].plot(clm.monthly_fit.index, clm.monthly_fit.values, '-o', color='darkorange', label=r2)\n",
    "axs[1, 0].legend(prop={'size': 12}, loc=1)\n",
    "axs[1, 0].set_title('Oregon Offshore')\n",
    "\n",
    "# calculate the monthly climatologies for the Oregon Shelf mooring and group the data monthly \n",
    "num = 0\n",
    "clm.fit(pco2a[num], 'partial_pressure_co2_ssw')\n",
    "r2 = '2-Cycle: R$^2$ = %.3f' % clm.regression['variance_explained'][0]\n",
    "mnthly_pco2 = pco2a[num].resample(time='M').mean()\n",
    "grps_pco2 = mnthly_pco2.groupby('time.month')\n",
    "\n",
    "# Plot the Oregon Shelf data\n",
    "for grp in grps_pco2:\n",
    "    axs[1, 1].plot(grp[1].time.to_index().strftime('%m').astype(int), grp[1]['partial_pressure_co2_ssw'],\n",
    "                   'o', color='lightgrey')\n",
    "axs[1, 1].plot(region_fco2[:, 0], region_fco2[:, 5], '-', color='royalblue', label=r'North Pacific')\n",
    "axs[1, 1].plot(clm.monthly_fit.index, clm.monthly_fit.values, '-o', color='darkorange', label=r2)\n",
    "axs[1, 1].legend(prop={'size': 12}, loc=1)\n",
    "axs[1, 1].set_title('Oregon Shelf')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.set(ylabel='pCO$^2$ ($\\mu$atm)')\n",
    "    ax.set_xticks(np.arange(1, 13))\n",
    "    ax.set_xticklabels(months)\n",
    "    ax.set_xlim((0.5, 12.5))\n",
    "    ax.set_ylim((150, 500))\n",
    "    \n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    \n",
    "plt.show()\n",
    "fig.savefig(os.path.join('regional_pco2_comparisons.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c224b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Plot the PHSEN data alongside Fassbender et al 2018 ######\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.set_size_inches(17, 11)\n",
    "\n",
    "# calculate the monthly climatologies for the Washington Offshore mooring and group the data monthly \n",
    "num = 3\n",
    "clm.fit(phsen[num], 'seawater_ph')\n",
    "r2 = r'2-Cycle: R$^2$ = %.3f' % clm.regression['variance_explained'][0]\n",
    "mnthly_ph = phsen[num].resample(time='M').mean()\n",
    "grps_ph = mnthly_ph.groupby('time.month')\n",
    "\n",
    "# Plot the Washington Offshore data\n",
    "for grp in grps_ph:\n",
    "    axs[0, 0].plot(grp[1].time.to_index().strftime('%m').astype(int), grp[1]['seawater_ph'],\n",
    "                   'o', color='lightgrey')\n",
    "axs[0, 0].plot(buoy_ph[:, 0], buoy_ph[:, 4], '-k', label='Cape Elizabeth')\n",
    "axs[0, 0].plot(buoy_ph[:, 0], buoy_ph[:, 4] - buoy_ph[:, 5], ':k', \n",
    "               buoy_ph[:, 0], buoy_ph[:, 4] + buoy_ph[:, 5], ':k')\n",
    "axs[0, 0].plot(region_ph[:, 0], region_ph[:, 3], '-', color='royalblue', label='Outer Coast')\n",
    "axs[0, 0].plot(clm.monthly_fit.index, clm.monthly_fit.values, '-o', color='darkorange', label=r2)\n",
    "axs[0, 0].legend(prop={'size': 12}, loc=1)\n",
    "axs[0, 0].set_title('Washington Offshore')\n",
    "\n",
    "# calculate the monthly climatologies for the Washington Shelf mooring and group the data monthly \n",
    "num = 2\n",
    "clm.fit(phsen[num], 'seawater_ph')\n",
    "r2 = '2-Cycle: R$^2$ = %.3f' % clm.regression['variance_explained'][0]\n",
    "mnthly_ph = phsen[num].resample(time='M').mean()\n",
    "grps_ph = mnthly_ph.groupby('time.month')\n",
    "\n",
    "# Plot the Washington Shelf data\n",
    "for grp in grps_ph:\n",
    "    axs[0, 1].plot(grp[1].time.to_index().strftime('%m').astype(int), grp[1]['seawater_ph'],\n",
    "                   'o', color='lightgrey')\n",
    "axs[0, 1].plot(buoy_ph[:, 0], buoy_ph[:, 4], '-k', label='Cape Elizabeth')\n",
    "axs[0, 1].plot(buoy_ph[:, 0], buoy_ph[:, 4] - buoy_ph[:, 5], ':k', \n",
    "               buoy_ph[:, 0], buoy_ph[:, 4] + buoy_ph[:, 5], ':k')\n",
    "axs[0, 1].plot(region_ph[:, 0], region_ph[:, 3], '-', color='royalblue', label='Outer Coast')\n",
    "axs[0, 1].plot(clm.monthly_fit.index, clm.monthly_fit.values, '-o', color='darkorange', label=r2)\n",
    "axs[0, 1].legend(prop={'size': 12}, loc=1)\n",
    "axs[0, 1].set_title('Washington Shelf')\n",
    "\n",
    "# calculate the monthly climatologies for the Oregon Offshore mooring and group the data monthly \n",
    "num = 1\n",
    "clm.fit(phsen[num], 'seawater_ph')\n",
    "r2 = '2-Cycle: R$^2$ = %.3f' % clm.regression['variance_explained'][0]\n",
    "mnthly_ph = phsen[num].resample(time='M').mean()\n",
    "grps_ph = mnthly_ph.groupby('time.month')\n",
    "\n",
    "# Plot the Oregon Offshore data\n",
    "for grp in grps_ph:\n",
    "    axs[1, 0].plot(grp[1].time.to_index().strftime('%m').astype(int), grp[1]['seawater_ph'],\n",
    "                   'o', color='lightgrey')\n",
    "axs[1, 0].plot(region_ph[:, 0], region_ph[:, 5], '-', color='royalblue', label=r'North Pacific')\n",
    "axs[1, 0].plot(clm.monthly_fit.index, clm.monthly_fit.values, '-o', color='darkorange', label=r2)\n",
    "axs[1, 0].legend(prop={'size': 12}, loc=1)\n",
    "axs[1, 0].set_title('Oregon Offshore')\n",
    "\n",
    "# calculate the monthly climatologies for the Oregon Shelf mooring and group the data monthly \n",
    "num = 0\n",
    "clm.fit(phsen[num], 'seawater_ph')\n",
    "r2 = '2-Cycle: R$^2$ = %.3f' % clm.regression['variance_explained'][0]\n",
    "mnthly_ph = phsen[num].resample(time='M').mean()\n",
    "grps_ph = mnthly_ph.groupby('time.month')\n",
    "\n",
    "# Plot the Oregon Shelf data\n",
    "for grp in grps_ph:\n",
    "    axs[1, 1].plot(grp[1].time.to_index().strftime('%m').astype(int), grp[1]['seawater_ph'],\n",
    "                   'o', color='lightgrey')\n",
    "axs[1, 1].plot(region_ph[:, 0], region_ph[:, 5], '-', color='royalblue', label=r'North Pacific')\n",
    "axs[1, 1].plot(clm.monthly_fit.index, clm.monthly_fit.values, '-o', color='darkorange', label=r2)\n",
    "axs[1, 1].legend(prop={'size': 12}, loc=1)\n",
    "axs[1, 1].set_title('Oregon Shelf')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.set(ylabel='pH')\n",
    "    ax.set_xticks(np.arange(1, 13))\n",
    "    ax.set_xticklabels(months)\n",
    "    ax.set_xlim((0.5, 12.5))\n",
    "    ax.set_ylim((7.9, 8.4))\n",
    "    \n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    \n",
    "plt.show()\n",
    "fig.savefig('regional_ph_comparisons.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ooi",
   "language": "python",
   "name": "ooi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
